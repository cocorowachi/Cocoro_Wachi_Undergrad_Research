{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07fddf51-c6b7-4b31-b939-97d33e52d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime, date, timedelta\n",
    "from dateutil.relativedelta import relativedelta, SU\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from functools import reduce\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a416c8f-a0d5-44eb-b62d-c65a40b28f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory = \"C:/Users/wachic/OneDrive - Milwaukee School of Engineering/Documents/GitHub/Undergrad_Research/\"\n",
    "\n",
    "# Naming convention\n",
    "# MMSD_sewerflow_all_dailyavg_df\n",
    "# 1.  [MMSD, USGS] Where the source is\n",
    "# 2.  [sewerflow, precip, streamflow] What the data measures\n",
    "# 3.  [all, dry, wet] what season it includes\n",
    "# 4-n What ever operation has been done to the data\n",
    "# n+1 [df, periods, csv] data type\n",
    "\n",
    "USGS_stream_flow_all_df = pd.read_csv(working_directory + \"USGS 04087030 Streamflow Cleaned.csv\")\n",
    "MMSD_sewerflow_all_df = pd.read_csv(working_directory + \"MMSD Sewer Flow Cleaned.csv\")\n",
    "MMSD_flow_and_precip_all_df = pd.read_csv(working_directory + \"MMSD Flow and Precipitation Cleaned.csv\")\n",
    "MMSD_precip_all_df = pd.read_csv(working_directory + \"MMSD Precipitation Raw Data Cleaned.csv\")\n",
    "\n",
    "df_list = [USGS_stream_flow_all_df,\n",
    "           MMSD_sewerflow_all_df,\n",
    "           MMSD_flow_and_precip_all_df,\n",
    "           MMSD_precip_all_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b71988-fd09-458f-b72a-adc504c4f22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_list:\n",
    "    df['Date Time'] = pd.to_datetime(df['Date Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e90e78ad-448f-456d-bf9c-c7134fe480c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export(df, name='export_df'):\n",
    "    csv = df.to_csv(f'{name}.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e570d4f7-094a-4dbe-818a-7d0adae3f6df",
   "metadata": {},
   "source": [
    "### Luedke model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9cea10a-1020-48aa-abf9-63650b192f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_mirrored_rows(df, num_rows=30):\n",
    "    \"\"\"\n",
    "    Insert chronologically mirrored data point at head and tail of df\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    mirrored_rows_head = df.iloc[:num_rows].copy()\n",
    "    mirrored_rows_head = mirrored_rows_head.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "    mirrored_rows_tail = df.iloc[-num_rows:].copy()\n",
    "    mirrored_rows_tail = mirrored_rows_tail.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "    df_extended = pd.concat([mirrored_rows_head, df, mirrored_rows_tail], ignore_index=True)\n",
    "    \n",
    "    return df_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80493400-5586-491f-828f-21e7cbd9c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_avg(df, length=24):\n",
    "    \"\"\" \n",
    "    Finds moving average for past 24 hour\n",
    "    \"\"\"\n",
    "    df = insert_mirrored_rows(df.copy())\n",
    "    out_df = df.set_index('Date Time').rolling(window=length).mean().reset_index()\n",
    "    return out_df.iloc[30:-30].reset_index(drop=True)\n",
    "\n",
    "def normalize(df):\n",
    "    df_normalized = df.copy()\n",
    "    for col in df.columns[1:]:  # Skip the first column (time series)\n",
    "        df_normalized[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "    return df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92b50ac5-4240-40be-ab21-cc4d79f671c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def luedke_2_level(df, RWmax, time_step):\n",
    "    df = df.copy()\n",
    "    df_movingavg = moving_avg(df, time_step)\n",
    "    df_mavg_normalized = normalize(df_movingavg)\n",
    "    RWt = RWmax*df_mavg_normalized\n",
    "    return RWt\n",
    "def luedke_3_level(df, time_step=24):\n",
    "    df = df.copy()\n",
    "    df_movingavg = moving_avg(df, time_step)\n",
    "    df_mavg_normalized = 70 - (normalize(df)*40)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45b35e6-93d0-4f8f-8eda-b4bd4b929fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
