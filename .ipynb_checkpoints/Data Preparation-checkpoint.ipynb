{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9df9440-bf56-458b-856f-833551637a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "from datetime import datetime, date, timedelta\n",
    "from dateutil.relativedelta import relativedelta, SU\n",
    "\n",
    "from functools import reduce\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d27c26c9-e179-4f98-8ef8-21e4b2fca934",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory = \"C:/Users/wachic/OneDrive - Milwaukee School of Engineering/Documents/GitHub/Undergrad_Research/\"\n",
    "\n",
    "USGS_streamflow_df = pd.read_csv(working_directory + \"USGS 04087030 MF Streamflow.csv\",\n",
    "                                  dtype=\"object\", names=['USGS', 'Location', 'Date Time', 'Time Zone', 'Stream Flow', 'Quality'])\n",
    "MMSD_sewer_flow_df = pd.read_csv(working_directory + \"MMSD Sewer Flow Data.csv\",\n",
    "                                  dtype=\"object\", skiprows=[0, 2])\n",
    "MMSD_flow_and_precip_df = pd.read_csv(working_directory + \"MMSD Hourly Flow and Precipitation.csv\",\n",
    "                                  dtype=\"object\", skiprows=[0, 2])\n",
    "MMSD_precip_raw_df = pd.read_csv(working_directory + \"MMSD Precipitation Raw Data.csv\",\n",
    "                                  dtype=\"object\", skiprows=[0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3291da41-0ca3-4272-a514-f7cdd56ff537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CDT_days(start_year, end_year):\n",
    "    \"\"\"\n",
    "    Returns a list of of dates which CST->CDT happen, which is the second Sunday of March\n",
    "    \"\"\"\n",
    "    dates = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        # Get the first day of March\n",
    "        first_march = date(year, 3, 1)\n",
    "        # Find the second Sunday\n",
    "        second_sunday = first_march + relativedelta(weekday=SU(+2))\n",
    "        datetime_sunday = datetime(year, 3, second_sunday.day, 3, 0, 0)\n",
    "        dates.append(datetime_sunday)\n",
    "    return dates\n",
    "    \n",
    "def to_hourly_cum(df):\n",
    "    df = df.copy()\n",
    "    columns_to_subtract = [col for col in df.columns if col != 'Date Time']\n",
    "    copy_df = df[columns_to_subtract]\n",
    "    copy_df = copy_df.diff()\n",
    "    copy_df.loc[df['Date Time'].dt.hour == 0, columns_to_subtract] = df.loc[df['Date Time'].dt.hour == 0, columns_to_subtract]\n",
    "    out_df = pd.concat([df['Date Time'], copy_df], axis=1,ignore_index=True)\n",
    "    out_df.columns = df.columns\n",
    "    return out_df\n",
    "    \n",
    "def set_na(edit_df, with_na_df):\n",
    "    \"\"\"\n",
    "    re-sets any nan values from\n",
    "    \"\"\"\n",
    "    edit_df = edit_df.copy()\n",
    "    with_na_df = with_na_df.copy()\n",
    "    edit_df[with_na_df.isna()] = np.nan\n",
    "    return edit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1233a6d2-49df-422f-9da2-6397f439bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_time(df):\n",
    "    \"\"\"\n",
    "    Extract only datapoint at each hour marks.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['Date Time'] = pd.to_datetime(df['Date Time'])\n",
    "    df = df[df['Date Time'].dt.minute == 00]\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def clean_USGS_df(df):\n",
    "    \"\"\"\n",
    "    Unifies data from USGS.\n",
    "    Adjusts for transition from CST->CDT by adding a 2am with the same values as 1am.\n",
    "    \"\"\"\n",
    "    out_df = df.copy()\n",
    "    \n",
    "    # Preprocessing\n",
    "    out_df.replace('Ice', 0, inplace=True)\n",
    "    out_df['Stream Flow'] = pd.to_numeric(out_df['Stream Flow'], errors='coerce')\n",
    "    out_df = separate_time(out_df)\n",
    "    years = set(pd.to_datetime(get_CDT_days(2010, 2024)))  # Convert years to set for O(1) lookup\n",
    "\n",
    "    new_rows = []  # Collect new rows here\n",
    "    \n",
    "    # Add missing 2:00 AM entries for CDT transition\n",
    "    for i in range(len(out_df) - 1, 0, -1):\n",
    "        if out_df.iloc[i]['Date Time'] in years:\n",
    "            new_row = out_df.iloc[[i - 1]].copy()  # Copy to avoid reference issues\n",
    "            new_row.loc[:, 'Date Time'] += timedelta(hours=1)\n",
    "            new_rows.append((i, new_row))  # Store new row with insertion index\n",
    "\n",
    "    # Insert all new rows efficiently\n",
    "    if new_rows:\n",
    "        new_dataframes = []\n",
    "        last_idx = 0\n",
    "\n",
    "        for i, new_row in sorted(new_rows):  # Ensure order is maintained\n",
    "            new_dataframes.append(out_df.iloc[last_idx:i])  # Add previous chunk\n",
    "            new_dataframes.append(new_row)  # Add new row\n",
    "            last_idx = i\n",
    "        \n",
    "        new_dataframes.append(out_df.iloc[last_idx:])  # Add remaining data\n",
    "        out_df = pd.concat(new_dataframes, ignore_index=True)\n",
    "\n",
    "    # Clean numeric columns (faster method)\n",
    "    num_columns = out_df.select_dtypes(include='number').columns\n",
    "    out_df[num_columns] = out_df[num_columns].mask(out_df[num_columns] < 0).ffill()\n",
    "    \n",
    "    # Apply additional cleaning\n",
    "    out_df = set_na(out_df, df)\n",
    "    \n",
    "    return out_df[['Date Time', 'Stream Flow']]\n",
    "\n",
    "def clean_MMSD_df(df):\n",
    "    \"\"\"\n",
    "    Set of instructions to unify data from USGS\n",
    "    MMSD data is already adjusted for CST->CDT\n",
    "    \"\"\"\n",
    "    out_df = df.copy()\n",
    "    out_df.rename(columns={'Unnamed: 0':'Date Time'}, inplace=True)\n",
    "    cols = out_df.columns.drop('Date Time')\n",
    "    out_df[cols] = out_df[cols].apply(pd.to_numeric)\n",
    "    \n",
    "    out_df = separate_time(out_df)\n",
    "    num_columns = out_df.select_dtypes(include='number').columns\n",
    "    \n",
    "    # Clean numeric columns (faster method)\n",
    "    num_columns = out_df.select_dtypes(include='number').columns\n",
    "    out_df[num_columns] = out_df[num_columns].mask(out_df[num_columns] < 0).ffill()\n",
    "    \n",
    "    # Apply additional cleaning\n",
    "    out_df = set_na(out_df, df)\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69c99880-2ce9-477d-a775-d74b1749fe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "USGS_streamflow_df = clean_USGS_df(USGS_streamflow_df)\n",
    "MMSD_sewer_flow_df = clean_MMSD_df(MMSD_sewer_flow_df)\n",
    "MMSD_flow_and_precip_df = clean_MMSD_df(MMSD_flow_and_precip_df)\n",
    "MMSD_precip_raw_df = to_hourly_cum(clean_MMSD_df(MMSD_precip_raw_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ed9c8d8-ac1e-4800-8620-0ce2dcefbd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "USGS_streamflow_csv = USGS_streamflow_df.to_csv('USGS 04087030 Streamflow Cleaned.csv', index = False) \n",
    "MMSD_sewer_flow_csv = MMSD_sewer_flow_df.to_csv('MMSD Sewer Flow Cleaned.csv', index = False) \n",
    "MMSD_flow_and_precip_csv = MMSD_flow_and_precip_df.to_csv('MMSD Flow and Precipitation Cleaned.csv', index = False) \n",
    "MMSD_precip_raw_csv = MMSD_precip_raw_df.to_csv('MMSD Precipitation Raw Data Cleaned.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ff23e-81e1-4132-bc21-d12457be5219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9608fc-196b-43a9-9d3b-898aa655bb38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
