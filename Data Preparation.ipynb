{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9df9440-bf56-458b-856f-833551637a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "from datetime import datetime, date, timedelta\n",
    "from dateutil.relativedelta import relativedelta, SU\n",
    "\n",
    "from functools import reduce\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d27c26c9-e179-4f98-8ef8-21e4b2fca934",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory = \"C:/Users/wachic/OneDrive - Milwaukee School of Engineering/Documents/GitHub/Undergrad_Research/\"\n",
    "\n",
    "USGS_streamflow_df = pd.read_csv(working_directory + \"USGS 04087030 MF Streamflow.csv\",\n",
    "                                  dtype=\"object\", names=['USGS', 'Location', 'Date Time', 'Time Zone', 'Stream Flow', 'Quality'])\n",
    "MMSD_sewer_flow_df = pd.read_csv(working_directory + \"MMSD Sewer Flow Data.csv\",\n",
    "                                  dtype=\"object\", skiprows=[0, 2])\n",
    "MMSD_flow_and_precip_df = pd.read_csv(working_directory + \"MMSD Hourly Flow and Precipitation.csv\",\n",
    "                                  dtype=\"object\", skiprows=[0, 2])\n",
    "MMSD_precip_raw_df = pd.read_csv(working_directory + \"MMSD Precipitation Raw Data.csv\",\n",
    "                                  dtype=\"object\", skiprows=[0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3291da41-0ca3-4272-a514-f7cdd56ff537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CDT_days(start_year, end_year):\n",
    "    \"\"\"\n",
    "    Returns a list of of dates which CST->CDT happen, which is the second Sunday of March\n",
    "    \"\"\"\n",
    "    dates = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        # Get the first day of March\n",
    "        first_march = date(year, 3, 1)\n",
    "        # Find the second Sunday\n",
    "        second_sunday = first_march + relativedelta(weekday=SU(+2))\n",
    "        datetime_sunday = datetime(year, 3, second_sunday.day, 3, 0, 0)\n",
    "        dates.append(datetime_sunday)\n",
    "    return dates\n",
    "    \n",
    "def to_hourly_cum(df):\n",
    "    df = df.copy()\n",
    "    columns_to_subtract = [col for col in df.columns if col != 'Date Time']\n",
    "    copy_df = df[columns_to_subtract]\n",
    "    copy_df = copy_df.diff()\n",
    "    copy_df.loc[df['Date Time'].dt.hour == 0, columns_to_subtract] = df.loc[df['Date Time'].dt.hour == 0, columns_to_subtract]\n",
    "    out_df = pd.concat([df['Date Time'], copy_df], axis=1,ignore_index=True)\n",
    "    out_df.columns = df.columns\n",
    "    return out_df\n",
    "    \n",
    "def set_na(edit_df, with_na_df):\n",
    "    \"\"\"\n",
    "    re-sets any nan values from\n",
    "    \"\"\"\n",
    "    edit_df = edit_df.copy()\n",
    "    with_na_df = with_na_df.copy()\n",
    "    edit_df[with_na_df.isna()] = np.nan\n",
    "    return edit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1233a6d2-49df-422f-9da2-6397f439bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_time(df):\n",
    "    \"\"\"\n",
    "    Extract only datapoint at each hour marks.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['Date Time'] = pd.to_datetime(df['Date Time'])\n",
    "    df = df[df['Date Time'].dt.minute == 00]\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def clean_USGS_df(df):\n",
    "    \"\"\"\n",
    "    Set of instructions to unify data from USGS\n",
    "    Adjusts for transition from CST->CDT by adding a 2am with the same values as 1am.\n",
    "    \"\"\"\n",
    "    out_df = df.copy()\n",
    "\n",
    "    out_df.replace('Ice', 0, inplace=True)\n",
    "    out_df['Stream Flow'] = out_df['Stream Flow'].apply(pd.to_numeric)\n",
    "    out_df = separate_time(out_df)\n",
    "    years = get_CDT_days(2012, 2024)\n",
    "    # add datapoint for CDT -> CST. Second Sunday of March 2:00am\n",
    "    for i in range(len(out_df)-1, -1, -1):\n",
    "        if df.iloc[i]['Date Time'] in years:\n",
    "            new_row = df.iloc[[i-1]]\n",
    "            out_df.loc[i-1,'Date Time'] = out_df.loc[i-1,'Date Time'] + timedelta(hours=1)  \n",
    "            out_df = pd.concat([out_df.iloc[:i-1], new_row, df.iloc[i-1:]], ignore_index=True)\n",
    "            \n",
    "        # Select numeric columns\n",
    "    num_columns = out_df.select_dtypes(include='number').columns\n",
    "    \n",
    "    # Loop through each numeric column\n",
    "    for col in num_columns:\n",
    "        out_df[col] = out_df[col].mask(out_df[col] < 0).ffill()\n",
    "    out_df = set_na(out_df,df)\n",
    "    return out_df\n",
    "\n",
    "def clean_MMSD_df(df):\n",
    "    \"\"\"\n",
    "    Set of instructions to unify data from USGS\n",
    "    MMSD data is already adjusted for CST->CDT\n",
    "    \"\"\"\n",
    "    out_df = df.copy()\n",
    "    out_df.rename(columns={'Unnamed: 0':'Date Time'}, inplace=True)\n",
    "    cols = out_df.columns.drop('Date Time')\n",
    "    out_df[cols] = out_df[cols].apply(pd.to_numeric)\n",
    "    \n",
    "    out_df = separate_time(out_df)\n",
    "    num_columns = out_df.select_dtypes(include='number').columns\n",
    "    \n",
    "    # Loop through each numeric column\n",
    "    for col in num_columns:\n",
    "        out_df[col] = out_df[col].mask(out_df[col] < 0).ffill()\n",
    "    out_df = set_na(out_df,df)\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69c99880-2ce9-477d-a775-d74b1749fe60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.31 s\n",
      "Wall time: 5.5 s\n"
     ]
    }
   ],
   "source": [
    "USGS_streamflow_df = clean_USGS_df(USGS_streamflow_df)\n",
    "MMSD_sewer_flow_df = clean_MMSD_df(MMSD_sewer_flow_df)\n",
    "MMSD_flow_and_precip_df = clean_MMSD_df(MMSD_flow_and_precip_df)\n",
    "MMSD_precip_raw_df = to_hourly_cum(clean_MMSD_df(MMSD_precip_raw_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ed9c8d8-ac1e-4800-8620-0ce2dcefbd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "USGS_streamflow_csv = USGS_streamflow_df.to_csv('USGS 04087030 Streamflow Cleaned.csv', index = False) \n",
    "MMSD_sewer_flow_csv = MMSD_sewer_flow_df.to_csv('MMSD Sewer Flow Cleaned.csv', index = False) \n",
    "MMSD_flow_and_precip_csv = MMSD_flow_and_precip_df.to_csv('MMSD Flow and Precipitation Cleaned.csv', index = False) \n",
    "MMSD_precip_raw_csv = MMSD_precip_raw_df.to_csv('MMSD Precipitation Raw Data Cleaned.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ff23e-81e1-4132-bc21-d12457be5219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9608fc-196b-43a9-9d3b-898aa655bb38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
